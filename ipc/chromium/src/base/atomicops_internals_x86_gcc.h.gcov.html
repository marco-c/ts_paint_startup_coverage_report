<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - output.info - ipc/chromium/src/base/atomicops_internals_x86_gcc.h</title>
  <link rel="stylesheet" type="text/css" href="../../../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../../../index.html">top level</a> - <a href="index.html">ipc/chromium/src/base</a> - atomicops_internals_x86_gcc.h<span style="font-size: 80%;"> (source / <a href="atomicops_internals_x86_gcc.h.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">output.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">17</td>
            <td class="headerCovTableEntry">21</td>
            <td class="headerCovTableEntryMed">81.0 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2017-07-14 16:53:18</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">5</td>
            <td class="headerCovTableEntry">6</td>
            <td class="headerCovTableEntryMed">83.3 %</td>
          </tr>
          <tr>
            <td class="headerItem">Legend:</td>
            <td class="headerValueLeg">            Lines:
            <span class="coverLegendCov">hit</span>
            <span class="coverLegendNoCov">not hit</span>
</td>
            <td></td>
          </tr>
          <tr><td><img src="../../../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : /* -*- Mode: C++; tab-width: 8; indent-tabs-mode: nil; c-basic-offset: 2 -*- */</a>
<span class="lineNum">       2 </span>            : /* vim: set ts=8 sts=2 et sw=2 tw=80: */
<span class="lineNum">       3 </span>            : // Copyright (c) 2006-2008 The Chromium Authors. All rights reserved.
<span class="lineNum">       4 </span>            : // Use of this source code is governed by a BSD-style license that can be
<span class="lineNum">       5 </span>            : // found in the LICENSE file.
<span class="lineNum">       6 </span>            : 
<span class="lineNum">       7 </span>            : // This file is an internal atomic implementation, use base/atomicops.h instead.
<span class="lineNum">       8 </span>            : 
<span class="lineNum">       9 </span>            : #ifndef BASE_ATOMICOPS_INTERNALS_X86_GCC_H_
<span class="lineNum">      10 </span>            : #define BASE_ATOMICOPS_INTERNALS_X86_GCC_H_
<span class="lineNum">      11 </span>            : 
<span class="lineNum">      12 </span>            : // This struct is not part of the public API of this module; clients may not
<span class="lineNum">      13 </span>            : // use it.
<span class="lineNum">      14 </span>            : // Features of this x86.  Values may not be correct before main() is run,
<span class="lineNum">      15 </span>            : // but are set conservatively.
<span class="lineNum">      16 </span>            : struct AtomicOps_x86CPUFeatureStruct {
<span class="lineNum">      17 </span>            :   bool has_amd_lock_mb_bug; // Processor has AMD memory-barrier bug; do lfence
<span class="lineNum">      18 </span>            :                             // after acquire compare-and-swap.
<span class="lineNum">      19 </span>            :   bool has_sse2;            // Processor has SSE2.
<span class="lineNum">      20 </span>            : };
<span class="lineNum">      21 </span>            : extern struct AtomicOps_x86CPUFeatureStruct AtomicOps_Internalx86CPUFeatures;
<span class="lineNum">      22 </span>            : 
<span class="lineNum">      23 </span>            : #define ATOMICOPS_COMPILER_BARRIER() __asm__ __volatile__(&quot;&quot; : : : &quot;memory&quot;)
<span class="lineNum">      24 </span>            : 
<span class="lineNum">      25 </span>            : namespace base {
<span class="lineNum">      26 </span>            : namespace subtle {
<span class="lineNum">      27 </span>            : 
<span class="lineNum">      28 </span>            : // 32-bit low-level operations on any platform.
<span class="lineNum">      29 </span>            : 
<span class="lineNum">      30 </span>            : inline Atomic32 NoBarrier_CompareAndSwap(volatile Atomic32* ptr,
<span class="lineNum">      31 </span>            :                                          Atomic32 old_value,
<span class="lineNum">      32 </span>            :                                          Atomic32 new_value) {
<span class="lineNum">      33 </span>            :   Atomic32 prev;
<span class="lineNum">      34 </span>            :   __asm__ __volatile__(&quot;lock; cmpxchgl %1,%2&quot;
<span class="lineNum">      35 </span>            :                        : &quot;=a&quot; (prev)
<span class="lineNum">      36 </span>            :                        : &quot;q&quot; (new_value), &quot;m&quot; (*ptr), &quot;0&quot; (old_value)
<span class="lineNum">      37 </span>            :                        : &quot;memory&quot;);
<span class="lineNum">      38 </span>            :   return prev;
<span class="lineNum">      39 </span>            : }
<span class="lineNum">      40 </span>            : 
<span class="lineNum">      41 </span>            : inline Atomic32 NoBarrier_AtomicExchange(volatile Atomic32* ptr,
<span class="lineNum">      42 </span>            :                                          Atomic32 new_value) {
<span class="lineNum">      43 </span>            :   __asm__ __volatile__(&quot;xchgl %1,%0&quot;  // The lock prefix is implicit for xchg.
<span class="lineNum">      44 </span>            :                        : &quot;=r&quot; (new_value)
<span class="lineNum">      45 </span>            :                        : &quot;m&quot; (*ptr), &quot;0&quot; (new_value)
<span class="lineNum">      46 </span>            :                        : &quot;memory&quot;);
<span class="lineNum">      47 </span>            :   return new_value;  // Now it's the previous value.
<a name="48"><span class="lineNum">      48 </span>            : }</a>
<span class="lineNum">      49 </span>            : 
<span class="lineNum">      50 </span><span class="lineCov">         15 : inline Atomic32 NoBarrier_AtomicIncrement(volatile Atomic32* ptr,</span>
<span class="lineNum">      51 </span>            :                                           Atomic32 increment) {
<span class="lineNum">      52 </span><span class="lineCov">         15 :   Atomic32 temp = increment;</span>
<span class="lineNum">      53 </span>            :   __asm__ __volatile__(&quot;lock; xaddl %0,%1&quot;
<span class="lineNum">      54 </span>            :                        : &quot;+r&quot; (temp), &quot;+m&quot; (*ptr)
<span class="lineNum">      55 </span><span class="lineCov">         15 :                        : : &quot;memory&quot;);</span>
<span class="lineNum">      56 </span>            :   // temp now holds the old value of *ptr
<span class="lineNum">      57 </span><span class="lineCov">         15 :   return temp + increment;</span>
<span class="lineNum">      58 </span>            : }
<span class="lineNum">      59 </span>            : 
<span class="lineNum">      60 </span>            : inline Atomic32 Barrier_AtomicIncrement(volatile Atomic32* ptr,
<span class="lineNum">      61 </span>            :                                         Atomic32 increment) {
<span class="lineNum">      62 </span>            :   Atomic32 temp = increment;
<span class="lineNum">      63 </span>            :   __asm__ __volatile__(&quot;lock; xaddl %0,%1&quot;
<span class="lineNum">      64 </span>            :                        : &quot;+r&quot; (temp), &quot;+m&quot; (*ptr)
<span class="lineNum">      65 </span>            :                        : : &quot;memory&quot;);
<span class="lineNum">      66 </span>            :   // temp now holds the old value of *ptr
<span class="lineNum">      67 </span>            :   if (AtomicOps_Internalx86CPUFeatures.has_amd_lock_mb_bug) {
<span class="lineNum">      68 </span>            :     __asm__ __volatile__(&quot;lfence&quot; : : : &quot;memory&quot;);
<span class="lineNum">      69 </span>            :   }
<span class="lineNum">      70 </span>            :   return temp + increment;
<span class="lineNum">      71 </span>            : }
<span class="lineNum">      72 </span>            : 
<span class="lineNum">      73 </span>            : inline Atomic32 Acquire_CompareAndSwap(volatile Atomic32* ptr,
<span class="lineNum">      74 </span>            :                                        Atomic32 old_value,
<span class="lineNum">      75 </span>            :                                        Atomic32 new_value) {
<span class="lineNum">      76 </span>            :   Atomic32 x = NoBarrier_CompareAndSwap(ptr, old_value, new_value);
<span class="lineNum">      77 </span>            :   if (AtomicOps_Internalx86CPUFeatures.has_amd_lock_mb_bug) {
<span class="lineNum">      78 </span>            :     __asm__ __volatile__(&quot;lfence&quot; : : : &quot;memory&quot;);
<span class="lineNum">      79 </span>            :   }
<span class="lineNum">      80 </span>            :   return x;
<span class="lineNum">      81 </span>            : }
<span class="lineNum">      82 </span>            : 
<span class="lineNum">      83 </span>            : inline Atomic32 Release_CompareAndSwap(volatile Atomic32* ptr,
<span class="lineNum">      84 </span>            :                                        Atomic32 old_value,
<span class="lineNum">      85 </span>            :                                        Atomic32 new_value) {
<span class="lineNum">      86 </span>            :   return NoBarrier_CompareAndSwap(ptr, old_value, new_value);
<span class="lineNum">      87 </span>            : }
<span class="lineNum">      88 </span>            : 
<span class="lineNum">      89 </span>            : inline void NoBarrier_Store(volatile Atomic32* ptr, Atomic32 value) {
<span class="lineNum">      90 </span>            :   *ptr = value;
<span class="lineNum">      91 </span>            : }
<span class="lineNum">      92 </span>            : 
<span class="lineNum">      93 </span>            : #if defined(__x86_64__)
<span class="lineNum">      94 </span>            : 
<span class="lineNum">      95 </span>            : // 64-bit implementations of memory barrier can be simpler, because it
<span class="lineNum">      96 </span>            : // &quot;mfence&quot; is guaranteed to exist.
<span class="lineNum">      97 </span>            : inline void MemoryBarrier() {
<span class="lineNum">      98 </span>            :   __asm__ __volatile__(&quot;mfence&quot; : : : &quot;memory&quot;);
<span class="lineNum">      99 </span>            : }
<span class="lineNum">     100 </span>            : 
<span class="lineNum">     101 </span>            : inline void Acquire_Store(volatile Atomic32* ptr, Atomic32 value) {
<span class="lineNum">     102 </span>            :   *ptr = value;
<span class="lineNum">     103 </span>            :   MemoryBarrier();
<span class="lineNum">     104 </span>            : }
<span class="lineNum">     105 </span>            : 
<span class="lineNum">     106 </span>            : #else
<span class="lineNum">     107 </span>            : 
<span class="lineNum">     108 </span>            : inline void MemoryBarrier() {
<span class="lineNum">     109 </span>            :   if (AtomicOps_Internalx86CPUFeatures.has_sse2) {
<span class="lineNum">     110 </span>            :     __asm__ __volatile__(&quot;mfence&quot; : : : &quot;memory&quot;);
<span class="lineNum">     111 </span>            :   } else { // mfence is faster but not present on PIII
<span class="lineNum">     112 </span>            :     Atomic32 x = 0;
<span class="lineNum">     113 </span>            :     NoBarrier_AtomicExchange(&amp;x, 0);  // acts as a barrier on PIII
<span class="lineNum">     114 </span>            :   }
<span class="lineNum">     115 </span>            : }
<span class="lineNum">     116 </span>            : 
<span class="lineNum">     117 </span>            : inline void Acquire_Store(volatile Atomic32* ptr, Atomic32 value) {
<span class="lineNum">     118 </span>            :   if (AtomicOps_Internalx86CPUFeatures.has_sse2) {
<span class="lineNum">     119 </span>            :     *ptr = value;
<span class="lineNum">     120 </span>            :     __asm__ __volatile__(&quot;mfence&quot; : : : &quot;memory&quot;);
<span class="lineNum">     121 </span>            :   } else {
<span class="lineNum">     122 </span>            :     NoBarrier_AtomicExchange(ptr, value);
<span class="lineNum">     123 </span>            :                           // acts as a barrier on PIII
<span class="lineNum">     124 </span>            :   }
<span class="lineNum">     125 </span>            : }
<span class="lineNum">     126 </span>            : #endif
<span class="lineNum">     127 </span>            : 
<span class="lineNum">     128 </span>            : inline void Release_Store(volatile Atomic32* ptr, Atomic32 value) {
<span class="lineNum">     129 </span>            :   ATOMICOPS_COMPILER_BARRIER();
<span class="lineNum">     130 </span>            :   *ptr = value; // An x86 store acts as a release barrier.
<span class="lineNum">     131 </span>            :   // See comments in Atomic64 version of Release_Store(), below.
<span class="lineNum">     132 </span>            : }
<span class="lineNum">     133 </span>            : 
<span class="lineNum">     134 </span>            : inline Atomic32 NoBarrier_Load(volatile const Atomic32* ptr) {
<span class="lineNum">     135 </span>            :   return *ptr;
<span class="lineNum">     136 </span>            : }
<span class="lineNum">     137 </span>            : 
<span class="lineNum">     138 </span>            : inline Atomic32 Acquire_Load(volatile const Atomic32* ptr) {
<span class="lineNum">     139 </span>            :   Atomic32 value = *ptr; // An x86 load acts as a acquire barrier.
<span class="lineNum">     140 </span>            :   // See comments in Atomic64 version of Release_Store(), below.
<span class="lineNum">     141 </span>            :   ATOMICOPS_COMPILER_BARRIER();
<span class="lineNum">     142 </span>            :   return value;
<span class="lineNum">     143 </span>            : }
<span class="lineNum">     144 </span>            : 
<span class="lineNum">     145 </span>            : inline Atomic32 Release_Load(volatile const Atomic32* ptr) {
<span class="lineNum">     146 </span>            :   MemoryBarrier();
<span class="lineNum">     147 </span>            :   return *ptr;
<span class="lineNum">     148 </span>            : }
<span class="lineNum">     149 </span>            : 
<span class="lineNum">     150 </span>            : #if defined(__x86_64__)
<span class="lineNum">     151 </span>            : 
<a name="152"><span class="lineNum">     152 </span>            : // 64-bit low-level operations on 64-bit platform.</a>
<span class="lineNum">     153 </span>            : 
<span class="lineNum">     154 </span><span class="lineCov">          3 : inline Atomic64 NoBarrier_CompareAndSwap(volatile Atomic64* ptr,</span>
<span class="lineNum">     155 </span>            :                                          Atomic64 old_value,
<span class="lineNum">     156 </span>            :                                          Atomic64 new_value) {
<span class="lineNum">     157 </span>            :   Atomic64 prev;
<span class="lineNum">     158 </span>            :   __asm__ __volatile__(&quot;lock; cmpxchgq %1,%2&quot;
<span class="lineNum">     159 </span>            :                        : &quot;=a&quot; (prev)
<span class="lineNum">     160 </span>            :                        : &quot;q&quot; (new_value), &quot;m&quot; (*ptr), &quot;0&quot; (old_value)
<span class="lineNum">     161 </span><span class="lineCov">          3 :                        : &quot;memory&quot;);</span>
<span class="lineNum">     162 </span><span class="lineCov">          3 :   return prev;</span>
<a name="163"><span class="lineNum">     163 </span>            : }</a>
<span class="lineNum">     164 </span>            : 
<span class="lineNum">     165 </span><span class="lineNoCov">          0 : inline Atomic64 NoBarrier_AtomicExchange(volatile Atomic64* ptr,</span>
<span class="lineNum">     166 </span>            :                                          Atomic64 new_value) {
<span class="lineNum">     167 </span>            :   __asm__ __volatile__(&quot;xchgq %1,%0&quot;  // The lock prefix is implicit for xchg.
<span class="lineNum">     168 </span>            :                        : &quot;=r&quot; (new_value)
<span class="lineNum">     169 </span>            :                        : &quot;m&quot; (*ptr), &quot;0&quot; (new_value)
<span class="lineNum">     170 </span><span class="lineNoCov">          0 :                        : &quot;memory&quot;);</span>
<span class="lineNum">     171 </span><span class="lineNoCov">          0 :   return new_value;  // Now it's the previous value.</span>
<span class="lineNum">     172 </span>            : }
<span class="lineNum">     173 </span>            : 
<span class="lineNum">     174 </span>            : inline Atomic64 NoBarrier_AtomicIncrement(volatile Atomic64* ptr,
<span class="lineNum">     175 </span>            :                                           Atomic64 increment) {
<span class="lineNum">     176 </span>            :   Atomic64 temp = increment;
<span class="lineNum">     177 </span>            :   __asm__ __volatile__(&quot;lock; xaddq %0,%1&quot;
<span class="lineNum">     178 </span>            :                        : &quot;+r&quot; (temp), &quot;+m&quot; (*ptr)
<span class="lineNum">     179 </span>            :                        : : &quot;memory&quot;);
<span class="lineNum">     180 </span>            :   // temp now contains the previous value of *ptr
<span class="lineNum">     181 </span>            :   return temp + increment;
<span class="lineNum">     182 </span>            : }
<span class="lineNum">     183 </span>            : 
<span class="lineNum">     184 </span>            : inline Atomic64 Barrier_AtomicIncrement(volatile Atomic64* ptr,
<span class="lineNum">     185 </span>            :                                         Atomic64 increment) {
<span class="lineNum">     186 </span>            :   Atomic64 temp = increment;
<span class="lineNum">     187 </span>            :   __asm__ __volatile__(&quot;lock; xaddq %0,%1&quot;
<span class="lineNum">     188 </span>            :                        : &quot;+r&quot; (temp), &quot;+m&quot; (*ptr)
<span class="lineNum">     189 </span>            :                        : : &quot;memory&quot;);
<span class="lineNum">     190 </span>            :   // temp now contains the previous value of *ptr
<span class="lineNum">     191 </span>            :   if (AtomicOps_Internalx86CPUFeatures.has_amd_lock_mb_bug) {
<span class="lineNum">     192 </span>            :     __asm__ __volatile__(&quot;lfence&quot; : : : &quot;memory&quot;);
<span class="lineNum">     193 </span>            :   }
<span class="lineNum">     194 </span>            :   return temp + increment;
<span class="lineNum">     195 </span>            : }
<span class="lineNum">     196 </span>            : 
<span class="lineNum">     197 </span>            : inline void NoBarrier_Store(volatile Atomic64* ptr, Atomic64 value) {
<span class="lineNum">     198 </span>            :   *ptr = value;
<a name="199"><span class="lineNum">     199 </span>            : }</a>
<span class="lineNum">     200 </span>            : 
<span class="lineNum">     201 </span><span class="lineCov">          3 : inline Atomic64 Acquire_CompareAndSwap(volatile Atomic64* ptr,</span>
<span class="lineNum">     202 </span>            :                                        Atomic64 old_value,
<span class="lineNum">     203 </span>            :                                        Atomic64 new_value) {
<span class="lineNum">     204 </span><span class="lineCov">          3 :   Atomic64 x = NoBarrier_CompareAndSwap(ptr, old_value, new_value);</span>
<span class="lineNum">     205 </span>            :   /* XXX/cjones: no idea if this is necessary... */
<span class="lineNum">     206 </span><span class="lineCov">          3 :   if (AtomicOps_Internalx86CPUFeatures.has_amd_lock_mb_bug) {</span>
<span class="lineNum">     207 </span><span class="lineNoCov">          0 :     __asm__ __volatile__(&quot;lfence&quot; : : : &quot;memory&quot;);</span>
<span class="lineNum">     208 </span>            :   }
<span class="lineNum">     209 </span><span class="lineCov">          3 :   return x;</span>
<span class="lineNum">     210 </span>            : }
<span class="lineNum">     211 </span>            : 
<span class="lineNum">     212 </span>            : inline void Acquire_Store(volatile Atomic64* ptr, Atomic64 value) {
<span class="lineNum">     213 </span>            :   *ptr = value;
<span class="lineNum">     214 </span>            :   MemoryBarrier();
<a name="215"><span class="lineNum">     215 </span>            : }</a>
<span class="lineNum">     216 </span>            : 
<span class="lineNum">     217 </span><span class="lineCov">          3 : inline void Release_Store(volatile Atomic64* ptr, Atomic64 value) {</span>
<span class="lineNum">     218 </span><span class="lineCov">          3 :   ATOMICOPS_COMPILER_BARRIER();</span>
<span class="lineNum">     219 </span>            : 
<span class="lineNum">     220 </span><span class="lineCov">          3 :   *ptr = value; // An x86 store acts as a release barrier</span>
<span class="lineNum">     221 </span>            :                 // for current AMD/Intel chips as of Jan 2008.
<span class="lineNum">     222 </span>            :                 // See also Acquire_Load(), below.
<span class="lineNum">     223 </span>            : 
<span class="lineNum">     224 </span>            :   // When new chips come out, check:
<span class="lineNum">     225 </span>            :   //  IA-32 Intel Architecture Software Developer's Manual, Volume 3:
<span class="lineNum">     226 </span>            :   //  System Programming Guide, Chatper 7: Multiple-processor management,
<span class="lineNum">     227 </span>            :   //  Section 7.2, Memory Ordering.
<span class="lineNum">     228 </span>            :   // Last seen at:
<span class="lineNum">     229 </span>            :   //   http://developer.intel.com/design/pentium4/manuals/index_new.htm
<span class="lineNum">     230 </span>            :   //
<span class="lineNum">     231 </span>            :   // x86 stores/loads fail to act as barriers for a few instructions (clflush
<span class="lineNum">     232 </span>            :   // maskmovdqu maskmovq movntdq movnti movntpd movntps movntq) but these are
<span class="lineNum">     233 </span>            :   // not generated by the compiler, and are rare.  Users of these instructions
<span class="lineNum">     234 </span>            :   // need to know about cache behaviour in any case since all of these involve
<span class="lineNum">     235 </span>            :   // either flushing cache lines or non-temporal cache hints.
<a name="236"><span class="lineNum">     236 </span><span class="lineCov">          3 : }</span></a>
<span class="lineNum">     237 </span>            : 
<span class="lineNum">     238 </span><span class="lineCov">         32 : inline Atomic64 NoBarrier_Load(volatile const Atomic64* ptr) {</span>
<span class="lineNum">     239 </span><span class="lineCov">         32 :   return *ptr;</span>
<span class="lineNum">     240 </span>            : }
<span class="lineNum">     241 </span>            : 
<span class="lineNum">     242 </span>            : inline Atomic64 Acquire_Load(volatile const Atomic64* ptr) {
<span class="lineNum">     243 </span>            :   Atomic64 value = *ptr; // An x86 load acts as a acquire barrier,
<span class="lineNum">     244 </span>            :                          // for current AMD/Intel chips as of Jan 2008.
<span class="lineNum">     245 </span>            :                          // See also Release_Store(), above.
<span class="lineNum">     246 </span>            :   ATOMICOPS_COMPILER_BARRIER();
<span class="lineNum">     247 </span>            :   return value;
<span class="lineNum">     248 </span>            : }
<span class="lineNum">     249 </span>            : 
<span class="lineNum">     250 </span>            : inline Atomic64 Release_Load(volatile const Atomic64* ptr) {
<span class="lineNum">     251 </span>            :   MemoryBarrier();
<span class="lineNum">     252 </span>            :   return *ptr;
<span class="lineNum">     253 </span>            : }
<span class="lineNum">     254 </span>            : #endif  // defined(__x86_64__)
<span class="lineNum">     255 </span>            : 
<span class="lineNum">     256 </span>            : } // namespace base::subtle
<span class="lineNum">     257 </span>            : } // namespace base
<span class="lineNum">     258 </span>            : 
<span class="lineNum">     259 </span>            : #undef ATOMICOPS_COMPILER_BARRIER
<span class="lineNum">     260 </span>            : 
<span class="lineNum">     261 </span>            : #endif  // BASE_ATOMICOPS_INTERNALS_X86_GCC_H_
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.13</a></td></tr>
  </table>
  <br>

</body>
</html>
